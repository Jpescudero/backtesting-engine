{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Barridas de apertura: análisis cuantitativo de reversión\n",
        "\n",
        "Notebook guiado para detectar barridas de apertura (sweeps), etiquetar los eventos con triple barrier y estudiar su probabilidad de reversión.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Cargar entorno del motor\n",
        "- Importa utilidades del motor de backtesting (data loader, analytics, utils).\n",
        "- Carga el CSV bruto del usuario con columnas estándar: `timestamp`, `open`, `high`, `low`, `close`, `volume`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.data.feeds import NPZOHLCVFeed\n",
        "from src.analytics.metrics import equity_curve_metrics\n",
        "from src.utils.risk import compute_position_size\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "sns.set(style='whitegrid')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Ruta al CSV intradía del usuario\n",
        "csv_path = Path('data/user_intraday.csv')\n",
        "\n",
        "# Carga del dataset\n",
        "df_raw = pd.read_csv(csv_path, parse_dates=['timestamp'])\n",
        "df_raw = df_raw.rename(columns=str.lower)\n",
        "df_raw = df_raw.sort_values('timestamp').set_index('timestamp')\n",
        "df_raw.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Construcción del dataset intradía\n",
        "- Opcional: resamplear a una granularidad homogénea (ej. 1m).\n",
        "- Añadir métricas: ATR(14), volumen relativo (RVOL), rango, true range (TR) y retornos futuros.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Parámetros de preprocesado\n",
        "resample_rule = '1min'  # Usa None si ya está a 1m\n",
        "atr_window = 14\n",
        "\n",
        "df = df_raw.copy()\n",
        "if resample_rule:\n",
        "    ohlc = {\n",
        "        'open': 'first',\n",
        "        'high': 'max',\n",
        "        'low': 'min',\n",
        "        'close': 'last',\n",
        "        'volume': 'sum',\n",
        "    }\n",
        "    df = df.resample(resample_rule).apply(ohlc).dropna(how='any')\n",
        "\n",
        "# Métricas básicas\n",
        "df['rango'] = df['high'] - df['low']\n",
        "prev_close = df['close'].shift(1)\n",
        "components = pd.concat([df['high'] - prev_close, prev_close - df['low'], df['rango']], axis=1)\n",
        "df['tr'] = components.max(axis=1)\n",
        "df['atr'] = df['tr'].rolling(atr_window).mean()\n",
        "df['volumen_medio'] = df['volume'].rolling(atr_window).mean()\n",
        "df['rvol'] = df['volume'] / df['volumen_medio']\n",
        "df['return_5m'] = df['close'].pct_change(periods=5) * 100\n",
        "df['return_10m'] = df['close'].pct_change(periods=10) * 100\n",
        "df = df.dropna()\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detección de eventos de posible barrida\n",
        "Condiciones parametrizables: caída brusca, rango amplio vs ATR y volumen inusualmente alto.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def detect_sweep_events(\n",
        "    data: pd.DataFrame,\n",
        "    x_pct: float = 0.5,\n",
        "    k: float = 1.5,\n",
        "    rvol_percentile: float = 0.8,\n",
        ") -> pd.DataFrame:\n",
        "    \"Filtra barras que cumplan con el patrón de barrida.\"\n",
        "    threshold = data['rvol'].quantile(rvol_percentile)\n",
        "    conditions = (\n",
        "        (data['return_5m'] < -x_pct)\n",
        "        & (data['rango'] > k * data['atr'])\n",
        "        & (data['rvol'] > threshold)\n",
        "    )\n",
        "    events = data.loc[conditions].copy()\n",
        "    events['rvol_threshold'] = threshold\n",
        "    events['sweep_params'] = {'x_pct': x_pct, 'k': k, 'rvol_percentile': rvol_percentile}\n",
        "    return events\n",
        "\n",
        "events = detect_sweep_events(df, x_pct=0.5, k=1.5, rvol_percentile=0.85)\n",
        "events.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Etiquetado avanzado (triple barrier)\n",
        "Aplicamos la metodología de López de Prado con TP/SL en función del ATR y un horizonte máximo de 1h.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Dict, Any\n",
        "\n",
        "def apply_triple_barrier(\n",
        "    data: pd.DataFrame,\n",
        "    events: pd.DataFrame,\n",
        "    tp_mult: float = 1.5,\n",
        "    sl_mult: float = 1.0,\n",
        "    max_horizon: str = '60min',\n",
        ") -> pd.DataFrame:\n",
        "    labels = []\n",
        "    outcomes: list[Dict[str, Any]] = []\n",
        "    horizon_delta = pd.Timedelta(max_horizon)\n",
        "\n",
        "    for ts, row in events.iterrows():\n",
        "        entry = float(row['close'])\n",
        "        atr = float(row['atr'])\n",
        "        tp = entry + tp_mult * atr\n",
        "        sl = entry - sl_mult * atr\n",
        "\n",
        "        future = data.loc[ts : ts + horizon_delta]\n",
        "        hit_tp = future[future['high'] >= tp].head(1)\n",
        "        hit_sl = future[future['low'] <= sl].head(1)\n",
        "\n",
        "        tp_time = hit_tp.index[0] if not hit_tp.empty else None\n",
        "        sl_time = hit_sl.index[0] if not hit_sl.empty else None\n",
        "\n",
        "        if tp_time is not None and (sl_time is None or tp_time <= sl_time):\n",
        "            label = 1\n",
        "            exit_time = tp_time\n",
        "            exit_price = tp\n",
        "        elif sl_time is not None:\n",
        "            label = -1\n",
        "            exit_time = sl_time\n",
        "            exit_price = sl\n",
        "        else:\n",
        "            label = 0\n",
        "            exit_time = future.index[-1]\n",
        "            exit_price = float(future['close'].iloc[-1])\n",
        "\n",
        "        labels.append(label)\n",
        "        outcomes.append(\n",
        "            {\n",
        "                'entry_price': entry,\n",
        "                'exit_price': exit_price,\n",
        "                'exit_time': exit_time,\n",
        "                'tp': tp,\n",
        "                'sl': sl,\n",
        "                'horizon': max_horizon,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    labeled = events.copy()\n",
        "    labeled['label'] = labels\n",
        "    labeled = pd.concat([labeled, pd.DataFrame(outcomes, index=events.index)], axis=1)\n",
        "    labeled['holding_minutes'] = (labeled['exit_time'] - labeled.index).dt.total_seconds() / 60\n",
        "    labeled['pnl_pct'] = (labeled['exit_price'] / labeled['entry_price'] - 1) * 100\n",
        "    return labeled\n",
        "\n",
        "labeled_events = apply_triple_barrier(df, events, tp_mult=1.5, sl_mult=1.0, max_horizon='60min')\n",
        "labeled_events.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Estadística de probabilidad de reversal\n",
        "Calculamos la probabilidad de alcanzar TP, distribución de retornos futuros y comparación por volumen.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def forward_returns(data: pd.DataFrame, horizons=(5, 10, 15, 30, 60)) -> pd.DataFrame:\n",
        "    result = {}\n",
        "    for h in horizons:\n",
        "        result[f'return_{h}m_fwd'] = data['close'].pct_change(periods=h).shift(-h) * 100\n",
        "    return pd.DataFrame(result, index=data.index)\n",
        "\n",
        "fwd = forward_returns(df)\n",
        "labeled_events = labeled_events.join(fwd, how='left')\n",
        "\n",
        "p_tp = (labeled_events['label'] == 1).mean() if not labeled_events.empty else np.nan\n",
        "ret_columns = [c for c in labeled_events.columns if c.startswith('return_') and c.endswith('m_fwd')]\n",
        "ret_stats = labeled_events[ret_columns].describe() if ret_columns else pd.DataFrame()\n",
        "\n",
        "high_rvol_cut = df['rvol'].quantile(0.9)\n",
        "hi_volume_events = labeled_events[labeled_events['rvol'] > high_rvol_cut]\n",
        "normal_volume_events = labeled_events[labeled_events['rvol'] <= high_rvol_cut]\n",
        "\n",
        "p_tp_high = (hi_volume_events['label'] == 1).mean() if not hi_volume_events.empty else np.nan\n",
        "p_tp_normal = (normal_volume_events['label'] == 1).mean() if not normal_volume_events.empty else np.nan\n",
        "\n",
        "summary = {\n",
        "    'p_tp_global': p_tp,\n",
        "    'p_tp_high_rvol': p_tp_high,\n",
        "    'p_tp_normal': p_tp_normal,\n",
        "    'n_events': len(labeled_events),\n",
        "    'n_high_rvol': len(hi_volume_events),\n",
        "    'n_normal': len(normal_volume_events),\n",
        "}\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Curva de equity simulada: entrar long tras la barrida y salir con triple barrier\n",
        "equity = [1_000_000]\n",
        "eq_index = []\n",
        "for ts, row in labeled_events.iterrows():\n",
        "    eq_index.append(row['exit_time'])\n",
        "    equity.append(equity[-1] * (1 + row['pnl_pct'] / 100))\n",
        "\n",
        "equity_series = pd.Series(equity[1:], index=pd.to_datetime(eq_index)).sort_index()\n",
        "eq_metrics = equity_curve_metrics(equity_series) if not equity_series.empty else {}\n",
        "eq_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualización\n",
        "Incluimos ejemplos de barridas detectadas, heatmaps y distribución de outcomes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_sweep_example(data: pd.DataFrame, events: pd.DataFrame, window: int = 60):\n",
        "    if events.empty:\n",
        "        print('No hay eventos para mostrar')\n",
        "        return\n",
        "    ts = events.index[0]\n",
        "    segment = data.loc[ts - pd.Timedelta(minutes=window): ts + pd.Timedelta(minutes=window)]\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    ax.plot(segment.index, segment['close'], label='Close')\n",
        "    ax.axvline(ts, color='red', linestyle='--', label='Evento')\n",
        "    ax.set_title('Ejemplo de barrida detectada')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_sweep_example(df, labeled_events)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Heatmap: retorno esperado según RVOL y TR/ATR\n",
        "if not labeled_events.empty:\n",
        "    labeled_events['tr_atr_ratio'] = labeled_events['tr'] / labeled_events['atr']\n",
        "    labeled_events['rvol_bin'] = pd.qcut(labeled_events['rvol'], q=5, duplicates='drop')\n",
        "    labeled_events['tr_bin'] = pd.qcut(labeled_events['tr_atr_ratio'], q=5, duplicates='drop')\n",
        "    pivot = labeled_events.pivot_table(\n",
        "        values='pnl_pct', index='rvol_bin', columns='tr_bin', aggfunc='mean'\n",
        "    )\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.heatmap(pivot, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "    plt.title('Retorno medio (%) por RVOL y TR/ATR')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Distribución de outcomes del triple barrier\n",
        "if not labeled_events.empty:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.countplot(x='label', data=labeled_events)\n",
        "    plt.title('Distribución de etiquetas triple barrier')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusión automática\n",
        "Resumen textual de si existe edge, mejores condiciones y relación con volumen.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def auto_summary(stats: dict, eq_metrics: dict) -> str:\n",
        "    lines = []\n",
        "    p_tp_val = stats.get('p_tp_global', np.nan)\n",
        "    lines.append(f\"Probabilidad de TP: {p_tp_val:.2%}\" if not np.isnan(p_tp_val) else 'Probabilidad de TP: n/d')\n",
        "    if eq_metrics:\n",
        "        sharpe_val = eq_metrics.get('sharpe_ratio', float('nan'))\n",
        "        lines.append(f\"Sharpe simulado 1h: {sharpe_val:.2f}\")\n",
        "    else:\n",
        "        lines.append('Sharpe simulado 1h: n/d')\n",
        "    lines.append(f\"Eventos analizados: {stats.get('n_events', 0)}\")\n",
        "    high_rvol = stats.get('p_tp_high_rvol', np.nan)\n",
        "    normal_rvol = stats.get('p_tp_normal', np.nan)\n",
        "    if not np.isnan(high_rvol):\n",
        "        lines.append(f\"Más edge en rvol alto? p(TP|rvol>p90) = {high_rvol:.2%}\")\n",
        "    if not np.isnan(normal_rvol):\n",
        "        lines.append(f\"p(TP|rvol<=p90) = {normal_rvol:.2%}\")\n",
        "    lines.append('Ventana óptima: ajustar x_pct/k según mayor retorno medio en heatmap.')\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(auto_summary(summary, eq_metrics))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checklist de métricas calculadas\n",
        "- Probabilidad de reversal: `p_tp_global` y condicionada por volumen.\n",
        "- Expectativas condicionadas: estadísticos de `return_{5,10,15,30,60}m_fwd`.\n",
        "- Sharpe simulado de estrategia de entrada inmediata post-shock.\n",
        "- Autocorrelaciones pre/post evento se pueden añadir con `df['close'].pct_change().autocorr(lag)`.\n",
        "- Distribución de volumen y colas revisada con los percentiles de `rvol`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}